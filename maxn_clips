
## Extracting Video Snippets for MaxN in EventMeasure

# This script extracts video snippets for MaxN events annotated using EventMeasure software (https://www.seagis.com.au/event.html).
#
# Warning!!!! Running this code on large datasets will brick your machine as it is extracting MaxN for every species in every drop
#
# Authors: jacquomo.monk@utas.edu.au, justin.hulls@utas.edu.au
#
# Prerequisites:
# - A folder containing all BRUV video files in a directory named "Converted".
# - A database export from EventMeasure with the following files in the working directory:
#   - "\Points.txt"
#   - "\Metadata.csv" file structured according to GlobalArchive standards (see: https://marine-ecology.shinyapps.io/CheckEM/).
# - FFmpeg installed (https://www.ffmpeg.org/download.html).

# Clean up environment
rm(list=ls())

# Load required packages
library(tidyverse)
library(readxl)
library(lubridate)
library(sf)

## 1. Setup Working Directory
folder_path <- choose.dir() # Navigate to the working folder
setwd(folder_path)
getwd()

## 2. Define Metadata and Attributes
data.camera_model = "GoPro Hero10" #edit for your cameras
data.contact.primary ="neville.barrett@utas.edu.au" #add email for your primary contact person
data.contact.secondary = "jacquomo.monk@utas.edu.au" #add email for your secondary contact person	
data.funder = "Parks Australia"	#add funder names. If multiple delimit by semicolon
data.grant_no  = "DNP-MPA-2122-062" #(optional) add relevant grant numbers. If multiple delimit by semicolon

institute = "IMAS" #set this for your institute. should remain the same between uploads
platform = "IMAS_stereoROV" #set this for each platform format should remain the same between uploads 
campaign = "202408_Beagle_AMP" #set this for each campaign. format should remain the same between uploads
licence = "Creative Commons by Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) ]" #Set as appropriate 

## 3. Setup Folder Structure
base_dir <- file.path(campaign)
folders <- c("Highlight_Video", "MaxN_Video", "Representative_Video")
for (folder in folders) {
  dir_path <- file.path(base_dir, folder)
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
    message("Created folder: ", dir_path)
  } else {
    message("Folder already exists: ", dir_path)
  }
}

## 4. Load Marine Parks Shapefile (CAPAD for Australia)
mpa_url <- "https://gis.environment.gov.au/gispubmap/rest/services/ogc_services/CAPAD_Marine/MapServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json"
mpa <- st_read(mpa_url)
mpa <- st_make_valid(mpa)

## 5. Load Metadata File
meta <- read.csv(list.files(pattern = "*.csv")) %>%
  mutate(
    site = opcode,
    date_time = date_time,
    latitude = latitude_dd,
    longitude = longitude_dd,
    depth = depth_m, #needs to be a positive
    depth.zone = case_when(
      depth_m >= 0 & depth_m < 30 ~ "shallow",
      depth_m >= 30 & depth_m < 70 ~ "mesophotic",
      depth_m >= 70 & depth_m < 200 ~ "rariphotic",
      depth_m >= 200 & depth_m < 700 ~ "upper-slope",
      depth_m >= 700 & depth_m < 2000 ~ "mid-slope",
      depth_m >= 2000 & depth_m < 4000 ~ "lower-slope",
      depth_m >= 4000 & depth_m < 6000 ~ "abyss",
      depth_m >= 6000 ~ "hadal",
      TRUE ~ NA_character_
    ),
    camera_model = data.camera_model,
    contact.primary = data.contact.primary,
    contact.secondary = data.contact.secondary,
    licence = licence,
    funder = data.funder,
    grant.no = data.grant_no
  ) %>%
  select("site", "date_time", "latitude":"grant.no") %>%
  glimpse()

## 6. Perform Data Quality Checks
missing_values <- meta %>% summarise(across(everything(), ~ sum(is.na(.)))) %>% pivot_longer(everything(), names_to = "Column", values_to = "Missing_Count")
print("Missing values per column:")
print(missing_values)

duplicates <- meta %>%
  filter(duplicated(.))

if (nrow(duplicates) > 0) {
  print("Duplicate rows found:")
  print(duplicates)
} else {
  print("No duplicate rows found.")
}

## 7. Convert Metadata to Spatial Points and Assign MPAs
meta_sf <- st_as_sf(meta, coords = c("longitude", "latitude"), crs = 4326)
meta_mpa <- st_join(meta_sf, mpa, left = TRUE) %>%
  mutate(Name = replace_na(NAME, "Open"), IUCN = replace_na(IUCN, "Open")) %>%
  select(site, date_time, depth, depth.zone, camera_model, contact.primary, contact.secondary, licence, funder, grant.no, Name, IUCN) %>%
  rename(MPA.name = Name) %>%
  as.data.frame() %>%
  select(!c(geometry)) %>%
  glimpse()

## 8. Extract Frame Rates from Video Files
video_dir <- file.path(getwd(), "Converted")
video_files <- list.files(video_dir, pattern = "\\.(MP4|AVI)$", full.names = TRUE, ignore.case = TRUE)

get_video_fps <- function(video_path) {
  command <- paste("ffprobe -i", shQuote(video_path), "-show_entries stream=r_frame_rate -v quiet -of csv=\"p=0\"")
  fps <- system(command, intern = TRUE)
  fps_values <- as.numeric(unlist(strsplit(fps, "/")))
  fps_rate <- fps_values[1] / fps_values[2]
  return(fps_rate)
}

fps_table <- data.frame(Video = video_files, FPS = sapply(video_files, get_video_fps)) %>% mutate(Filename = basename(Video)) %>% glimpse()

## 9. Read EventMeasure Points File for MaxN Events
# List files that contain "Points" and end with ".txt".
file_path <- list.files(pattern = "Points.*\\.txt$", full.names = TRUE) %>%
  enframe(name = NULL, value = "file_path") %>%
  filter(str_detect(file_path, "_Points.*\\.txt$")) %>% #get rid of 3D points if these are in the same file
  pull(file_path)

# Check if any file was found and read it
if (length(file_path) > 0) {
  Points <- read_delim(file_path, delim = "\t") 
  head(Points)
} else {
  cat("No file with 'Points' in the name was found.")
}

## 10. Calculate MaxN from Points and combined with video files to set extraction time point based on frame
MaxN <- Points %>%
  mutate(
    Genus = ifelse(Genus == "", Family, Genus), # Replace empty Genus with Family
    Scientific = paste(Genus, Species, sep = " ") # Combine Genus and Species
  ) %>%
  group_by(OpCode, Scientific, Frame) %>%         # Group by OpCode, Scientific name, and Time
  dplyr::mutate(Number = as.numeric(Number)) %>%
  dplyr::summarise(maxn = sum(Number)) %>%         # Summarize the maximum number for each group
  dplyr::ungroup() %>%
  dplyr::group_by(OpCode, Scientific) %>%
  dplyr::slice(which.max(maxn)) %>%                # Keep the row with the max value for each species
  dplyr::ungroup() %>%
  arrange(OpCode, Scientific, Frame) %>%          # Sort by OpCode, Scientific, and Time
  left_join(select(Points, OpCode, Frame, Filename), by = c("OpCode", "Frame")) %>%  # Left join only Filename
  left_join(fps_table, by= join_by(Filename))%>%
  mutate(
    Time_in_seconds = Frame/FPS, # Convert Frames to seconds 
    clip_start_in_seconds = (round(Time_in_seconds - 10)),  # Start 10 seconds before MaxN
    clip_start_in_seconds = ifelse(clip_start_in_seconds < 0, 0, clip_start_in_seconds) # Prevent negative times
  ) %>%
  filter(!Scientific %in% c(" ","NA NA")) %>%                     # Filter out empty scientific names
  rename(site=OpCode)%>%
  glimpse()

  
## 11. Join MaxN and video files to get the path
combined <- as.data.frame(video_files) %>%
  mutate(Filename = str_extract(video_files, "[^/]+$")) %>%
  mutate(site = str_extract(Filename, "(?<=_)(\\d+_\\d+)(?=_)")) %>%  # Extracts "1_1" pattern. Edit as needed
  right_join(meta_mpa, by = "site") %>%             # Right join to ensure all Video parts rows are kept
  dplyr::select(!Filename) %>%
  right_join(MaxN, by = "site")%>%
  # dplyr::filter(maxn>=5)%>% #You may or may not want to use this filter to keep large schools (e.g. MaxN greater than 5)
  glimpse()


## 12. Setup output folder and path for video clips 
#Ensure the output directory exists
output_dir <- paste(getwd(),campaign,"MaxN_Video", sep= "/")
output_dir

## 13. Iterate over each row of 'combined' to process the video clips
for (i in 1:nrow(combined)) {
  
  # Get the video file path and name
  video_file <- combined$Filename[i]
  video_full_path <- file.path(video_dir, video_file)  # Correct path construction
  
  # Check if the file exists (to avoid errors)
  if (!file.exists(video_full_path)) {
    cat("File not found:", video_full_path, "\n")
    next  # Skip to next iteration if file doesn't exist
  }
  
  # Get the start time for the clip
  clip_start_time <- combined$clip_start_in_seconds[i]
  
  # Generate the output video file name using the format: Filename_Comment_Time.mp4
  clean_video_file <- gsub("\\.[^.]+$", "", video_file)  # Remove video extension from the filename
  
  # Ensure Scientific name is clean (remove unwanted characters or NAs)
  clean_name <- gsub("[^[:alnum:]_]", "_", combined$Scientific[i])
  if (is.na(  clean_name ) |   clean_name  == "") {
    clean_name  <- "Unknown"
  }
  
  # Use Time to ensure a unique filename
  output_video_name <- paste0(clean_video_file, "_", clean_name, "_", round(combined$Time[i],2), ".MP4")
  output_video_path <- file.path(output_dir, output_video_name)
  
  # Create the FFmpeg command for video clip extraction
  ffmpeg_command <- paste0(
    "ffmpeg -i \"", normalizePath(video_full_path, winslash = "/"), "\"",  # Input video file
    " -ss ", clip_start_time,               # Start time for the clip
    " -an ",                              # Exclude audio
    " -t 30 ",                              # Duration of the clip (30 seconds). Change as needed
    " -c:v libx264 -preset veryfast -crf 23 ",   # Compression settings
    " -profile:v high -level 4.2 ", #improves compatibility with web players
    " -movflags +faststart ", #places metadata at the beginning for faster playback
    "\"", normalizePath(output_video_path, winslash = "/"), "\""  # Output video file path
  )
  
  # Execute the FFmpeg command and capture the output
  cat("Running: ", ffmpeg_command, "\n")
  ffmpeg_output <- system(ffmpeg_command, intern = TRUE)
  
  # Print the ffmpeg output for debugging
  cat(ffmpeg_output, sep = "\n")
  
  # Check if the output file was created and has a valid size
  if (file.exists(output_video_path) && file.info(output_video_path)$size > 1024) {
    cat("Successfully created:", output_video_path, "\n")
  } else {
    cat("Failed to create a valid output file:", output_video_path, "\n")
  }
}

## 14. Format metadata and write out for highlight videos
# Get highlight video names and match back to metadata
maxn_files <- list.files(output_dir, pattern = "\\.(MP4)$", full.names = TRUE, ignore.case = TRUE)

# Extract filenames without the path
maxn_df <- data.frame(Filename.H = basename(maxn_files), stringsAsFactors = FALSE)%>%
  mutate(site = str_extract(Filename.H, "(?<=_)[A-Z](_\\d+)(?=_)")) %>%  # Extracts "B_23"  # Extracts "B_23" or similar patterns. Edit as needed
  # mutate(site = str_extract(Filename, "(?<=_)(\\d+_\\d+)(?=_)")) %>%  # Extracts "1_1" pattern. Edit as needed
  glimpse()

# Combine with combined metadata df
final.meta<-combined%>%
  left_join(maxn_df, by= "site")%>%
  dplyr::select(site,Scientific:IUCN,Filename.H)%>%
  rename(filename=Filename.H)%>%
  mutate(institute=institute)%>%
  glimpse()

write.csv(final.meta, file = file.path(output_dir, paste0(campaign, "_", "MaxN_Metadata.csv")), row.names = FALSE)
